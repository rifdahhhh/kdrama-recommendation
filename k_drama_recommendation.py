# -*- coding: utf-8 -*-
"""K-drama Recommendation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14uNjvpx5R3d3JczuToeboYSH5fLKukRW

Nama: Rifdah Hansya Rofifah

Email: rifdahiparifdah@gmail.com

ID Dicoding: rifdahhr
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow

"""Import library yang dibutuhkan"""

import pandas as pd
import re
import string
import tensorflow as tf_lib
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.pyplot as plt
import seaborn as sns


from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import precision_recall_fscore_support

"""# Data Understanding

Pada tahap ini, terdapat tiga file CSV yang akan digunakan, yaitu kdrama, reviews, dan actors.
"""

kdrama = pd.read_csv('/content/drive/MyDrive/Dataset ML/k-drama-rec/korean_drama.csv')
reviews = pd.read_csv('/content/drive/MyDrive/Dataset ML/k-drama-rec/reviews.csv')
actors = pd.read_csv('/content/drive/MyDrive/Dataset ML/k-drama-rec/wiki_actors.csv')

"""## K-Drama Variable

Variabel k-drama berisi mengenai informasi mengenai drama korea, seperti nama drama, tahun, sinopsis, dll.

Untuk mengetahui informasi secara umum, kita dapat memanggil fungsi info
"""

kdrama.info()

"""Ada missing value untuk dataframe kdrama yang nanti kita akan tangani di proses data preparation

Untuk mengetahui informasi secara umum, kita dapat memanggil fungsi info
"""

kdrama.head()

"""lihat isi yang ada pada kolom type"""

print('Banyak Type: ', len(kdrama.type.unique()))
print('Type: ', kdrama.type.unique())

"""kolom type hanya berisi 1 isi unik yaitu Drama

Lihat isi yang ada pada kolom country
"""

print('Banyak country: ', len(kdrama.country.unique()))
print('country: ', kdrama.country.unique())

"""Ternyata kolom country hanya berisi 1 isi unik yaitu South Korea

Karena nilai dari `type` dan `country` hanya memiliki 1 nilai yang sama untuk semua data, maka kita bisa drop kolom ini nanti.

## Reviews Variabel

Pada variabel reviews berisi mengenai ulasan dan rating drama korea dari users.

Untuk mengetahui informasi secara umum, kita dapat memanggil fungsi info
"""

reviews.info()

"""Bisa kita lihat bahwa di kolom reviews ada beberapa missing value di beberapa kolom, akan tetapi kita hanya mengambil kolom yang diperlukan."""

reviews.head()

"""## Actors Variable

Variabel actors berisi mengenai informasi actor korea dan drama yang diperani oleh actor tersebut.

Untuk mengetahui informasi secara umum, kita dapat memanggil fungsi info
"""

actors.info()

"""tidak terdapat missing value pada variabel actor"""

actors.head()

"""## EDA"""

# Visualisasi top 10 aktor dengan drama terbanyak
# Merge kdrama and actors data based on drama title
drama_actor_merge = pd.merge(kdrama, actors, on='drama_name', how='left')

# Group by actor name and count the number of dramas they appeared in
actor_drama_counts = drama_actor_merge.groupby('actor_name')['drama_name'].count().reset_index()
actor_drama_counts = actor_drama_counts.rename(columns={'drama_name': 'drama_count'})
actor_drama_counts = actor_drama_counts.sort_values('drama_count', ascending=False)

# Ambil 10 aktor dengan jumlah drama terbanyak
top_n = 10
top_actors = actor_drama_counts.head(top_n)

plt.figure(figsize=(12, 6))
sns.barplot(x='drama_count', y='actor_name', data=top_actors, palette='viridis')
plt.xlabel('Jumlah Drama')
plt.ylabel('Nama Aktor')
plt.title(f'Top {top_n} Aktor dengan Jumlah Drama Terbanyak')
plt.xticks(np.arange(0, top_actors['drama_count'].max() + 1, 2))
plt.gca().invert_yaxis()
plt.show()

"""Berdasarkan hasil visualiasi tersebut, aktor Lee Yoo Jin merupakan aktor paling banyak memerankan drama, yaitu sebanyak 18 drama."""

# buat visualisasi jumlah drama yang diproduksi pertahun
drama_per_tahun = kdrama.groupby('year')['drama_name'].count()

# Membuat visualisasi
plt.figure(figsize=(10, 6))
plt.plot(drama_per_tahun.index, drama_per_tahun.values)
plt.xlabel('Tahun')
plt.ylabel('Jumlah Drama')
plt.title('Jumlah Drama yang Diproduksi per Tahun')
plt.grid(True)
plt.show()

"""Tahun 2021 adalah tahun terbanyak memproduksi drama

# Data Preparation

## Data Preparation untuk Content-based Filtering

### Siapkan dataframe yang dibutuhkan

Variable yang dibutuhkan untum CBF adalah `kdrama` dan `actors`

lakukan merge variabel kdrama dan actors
"""

# merge kdrama dan actors
kdrama_info_df = pd.merge(kdrama, actors, on='drama_name', how='left')
kdrama_info_df.head()

"""drop kolom yang tidak diperlukan"""

# drop kolom yang tidak diperlukan
columns_to_drop = ['role', 'character_name', 'pop', 'content_rt', 'screenwriter', 'country', 'type', 'start_dt', 'end_dt', 'aired_on', 'org_net', 'rank']
kdrama_info_df = kdrama_info_df.drop(columns=columns_to_drop, errors='ignore')
kdrama_info_df.head(10)

"""lakukan grouping pada actor_name menjadi list supaya 1 drama bisa terdapat beberapa aktor dan tidak ada ada duplikasi data, masukkan ke dataframe baru `kdrama_grouped`"""

#  Lakukan grouping pada actors menjadi sebuah list
kdrama_grouped = kdrama_info_df.groupby('drama_name').agg({
    'kdrama_id': 'first',
    'actor_name': list,
    'year': 'first',
    'director': 'first',
    'tot_eps': 'first',
    'duration': 'first',
    'synopsis': 'first'
}).reset_index()

kdrama_grouped.head()

"""cek informasi df baru `dataframe_grouped`"""

kdrama_grouped.info()

"""cek missing value pada dataframe baru tersebut"""

# cek missing value
kdrama_grouped.isnull().sum()

"""Berdasarkan pengecekan tersebut, didapat kolom yang terdapat missing value yaitu kolom `director`, `duration`, dan `synopsis`.

Untuk kolom `director` lakukan pengisian dengan **string kosong**

untuk kolom `duration` diisi denan **mean**

untuk kolom `synopsis` diisi dengan **string kosong**
"""

# Mengatasi Missing value
kdrama_grouped['director'].fillna('', inplace=True)

mean_duration = kdrama_grouped['duration'].mean()
kdrama_grouped['duration'].fillna(mean_duration, inplace=True)

kdrama_grouped['synopsis'].fillna('', inplace=True)

# cek kembali missing value setelah dilakukan penanganan
kdrama_grouped.isnull().sum()

"""Sudah tidak ada missing value setelah dilakukan penanganan"""

# lihat statistik deskriptif pada kdrama_grouped
kdrama_grouped.describe()

"""Tidak ada keanehan pada dataframe tersebut, tahun dimulai dari 2015 hingga 2023"""

kdrama_grouped.head(10)

"""Dapat dilihat pada dataframe di atas ternyata masih ada nilai `nan` pada kolom actor_name, maka kita akan mengganti nilai tersebut dengan string kosong"""

# Ganti nilai NaN pada actor_name menggunakan string kosong
kdrama_grouped['actor_name'] = kdrama_grouped['actor_name'].fillna('')
kdrama_grouped.head()

"""Pada nilai director ada tanda ' dan kita akan hapus tanda kutip tersebut"""

# hapus tanda ' yang ada di kolom director
kdrama_grouped['director'] = kdrama_grouped['director'].str.replace("'", "")
kdrama_grouped.head()

"""split isi dari kolom `synopsis` menjadi dipisah per kata"""

# split synopsis
kdrama_grouped['synopsis'] = kdrama_grouped['synopsis'].apply(lambda x:x.split())
kdrama_grouped.head(1)

kdrama_grouped.info()

"""kolom `director` belum berupa list, maka kita harus ubah"""

# Ubah kolom 'director' menjadi list
kdrama_grouped['director'] = kdrama_grouped['director'].apply(lambda x: [x] if isinstance(x, str) else [])
kdrama_grouped.head()

"""Hapus spasi yang ada pada kolom `actor_name`, `director`, dan `synopsis`"""

# hapus spasi
kdrama_grouped['actor_name'] = kdrama_grouped['actor_name'].apply(lambda x: [str(i).replace(" ", "") for i in x])
kdrama_grouped['director'] = kdrama_grouped['director'].apply(lambda x: [str(i).replace(" ", "") for i in x])
kdrama_grouped['synopsis'] = kdrama_grouped['synopsis'].apply(lambda x: [str(i).replace(" ", "") for i in x])

kdrama_grouped.head()

"""buat kolom baru bernama `tags` yang menyatukan 3 kolom (synopsis, actor_name, dan director)"""

# kelompokkan kolom synopsis, actor_name, dan director ke dalam kolom tags
kdrama_grouped['tags'] = kdrama_grouped['synopsis'] + kdrama_grouped['actor_name'] + kdrama_grouped['director']
kdrama_grouped.head(1)

"""lihat tags pada indeks ke 0"""

kdrama_grouped['tags'][0]

"""gabungkan semua elemen dari tags ke dalam satu string dengan spasi sebagai pemisah

"""

kdrama_grouped['tags'] = kdrama_grouped['tags'].apply(lambda x: " ".join(x))
kdrama_grouped.head(1)

"""bisa dilihat pada kolom tags tersebut sudah menjadi sebuah kesatuan

"""

kdrama_grouped['tags'][0]

"""jika kita perhatikan kolom tags pada indeks ke 0 tersebut masih ada beberapa hal yang perlu kita bersihkan, seperti masih adanya uppercase, ada kata-kata yang tidak diperlukan, dan masih ada tanda baca."""

kdrama_grouped['tags'] = kdrama_grouped['tags'].apply(lambda x:x.lower()) # ubah menjadi lowercase
kdrama_grouped['tags'] = kdrama_grouped['tags'].apply(lambda x: re.sub(r"\(source:.*?\)", "", x)) # hapus source
kdrama_grouped['tags'] = kdrama_grouped['tags'].apply(lambda x: x.translate(str.maketrans("", "", string.punctuation)))  # Hapus tanda baca
kdrama_grouped['tags'][0]

"""Setelah cleaning selesai, buat dataframe baru"""

# buat dataframe kdrama_df
kdrama_df = kdrama_grouped[["kdrama_id", "drama_name", "tags"]]
kdrama_df.head()

"""### TF-IDF Vectorizer

Pada tahap ini, kita akan melakukan perhitungan tf-idf pada kolom tags
"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data cuisine
tf.fit(kdrama_df['tags'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

"""ubah teks dalam kolom "tags" pada dataset kdrama_df menjadi representasi vektor menggunakan TF-IDF dan tampilkan ukuran matriks hasil transformasi."""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(kdrama_df['tags'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""tampilkan sampel kecil dari matriks TF-IDF untuk mempermudah visualisasi"""

# Membuat dataframe untuk melihat tf-idf matrix
num_cols = tfidf_matrix.shape[1]
num_rows = tfidf_matrix.shape[0]

num_cols_to_sample = min(22, num_cols)
num_rows_to_sample = min(10, num_rows)

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=kdrama_df.drama_name
).sample(num_cols_to_sample, axis=1).sample(num_rows_to_sample, axis=0)

"""## Data Preparation untuk Collaborative Filtering

### Siapkan dataframe dengan kolom yang dibutuhkan

Pada Collaborative Filtering, hanya akan menggunakan varible reviews dan kdrama (hanya mengambil kolom kdrama_id)
"""

reviews.head()

"""gabungkan dataframe reviews dengan kdrama (hanya mengambil kolom kdrama_id nya saja pada df kdrama)"""

# merge reviews dengan kdrama (mengambil kdrama_id)
reviews_grouped = pd.merge(reviews, kdrama[['kdrama_id', 'drama_name']], left_on='title', right_on='drama_name', how='left')
reviews_grouped.head()

"""konversi user_id lalu buat mapping nya supaya dapat dilakukan perhitungan"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = reviews_grouped['user_id'].unique().tolist()
print('list user_id: ', user_ids)

# Melakukan encoding user_id
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke user_id
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

# Mapping userID ke dataframe user
reviews_grouped['user_encode'] = reviews_grouped['user_id'].map(user_to_user_encoded)
reviews_grouped.head()

"""Dapat dilihat terdapat kolom duplikat yang menampung judul drama korea, yaitu pada kolom title dan drama_name, sehingga kita harus drop salah satu kolom tersebut"""

# drop kolom title karena duplikat dati drama_name
reviews_grouped = reviews_grouped.drop('title', axis=1)
reviews_grouped.head()

"""Konversi nilai drama dan lakukan mapping supaya bisa dilakukan perhitungan"""

# Mengubah drama menjadi list tanpa nilai yang sama
dramas = reviews_grouped['kdrama_id'].unique().tolist()
print('list dramas: ', dramas)

# Melakukan encoding drama
drama_to_drama_encoded = {x: i for i, x in enumerate(dramas)}
print('encoded drama : ', drama_to_drama_encoded)

# Melakukan proses encoding angka ke ke drama
drama_encoded_to_drama = {i: x for i, x in enumerate(dramas)}
print('encoded angka ke drama: ', drama_encoded_to_drama)

# Mapping drama ke dataframe reviews_grouped
reviews_grouped['kdrama_encode'] = reviews_grouped['kdrama_id'].map(drama_to_drama_encoded)
reviews_grouped.head()

"""Hitung jumlah user dan cari nilai maksimum dan minimum dari overall_score"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah drama
num_drama = len(drama_to_drama_encoded)
print(num_drama)

# Nilai minimum overall_score
min_overall_score = min(reviews['overall_score'])

# Nilai maksimal overall_score
max_overall_score = max(reviews['overall_score'])

print('Number of User: {}, Number of drama: {}, Min overall_score: {}, Max overall_score: {}'.format(
    num_users, num_drama, min_overall_score, max_overall_score
))

"""Buat dataframe baru dengan kolom yang dibutuhkan"""

# buat dataframe dengan kolom-kolom yang dibutuhkan
reviews_df = reviews_grouped[['user_id', 'kdrama_id', 'drama_name', 'overall_score', 'user_encode', 'kdrama_encode']]
reviews_df.head()

"""### Split Data

Membagi data untuk training dan validasi
"""

# Membuat variabel x untuk mencocokkan data user dan kdrama menjadi satu value
x = reviews_df[['user_encode', 'kdrama_encode']].values

# Membuat variabel y untuk membuat rating dari hasil
y = reviews_df['overall_score'].apply(lambda x: (x - min_overall_score) / (max_overall_score - min_overall_score)).values

# Membagi menjadi 80% data train, 10% data validasi, dan 10% data test
train_indices = int(0.8 * reviews_df.shape[0])
val_indices = int(0.9 * reviews_df.shape[0])
x_train, x_val, x_test, y_train, y_val, y_test = (
    x[:train_indices],
    x[train_indices:val_indices],
    x[val_indices:],
    y[:train_indices],
    y[train_indices:val_indices],
    y[val_indices:]
)

print(x, y)

"""# Modeling

## Content-based Filtering

Setelah menghitung TF-IDF pada tahap data preparation, selanjutnya di modeling CBF ini kita akan hitung terlebih dahulu consine similarity nya

### Cosine Similarity
"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

""" tampilkan kemiripan antar drama berdasarkan similarity matrix tersebut"""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama drama
cosine_sim_df = pd.DataFrame(cosine_sim, index=kdrama_df['drama_name'], columns=kdrama_df['drama_name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap drama
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Mendapat Rekomendasi CBF

kita akan coba berikan rekomendasi drama berdasarkan kemiripan yang diberikan dan menampilkan k rekomendasi teratas
"""

def drama_recommendations(nama_drama, similarity_data=cosine_sim_df, items=kdrama_df[['drama_name', 'tags']], k=5):
    """
    Rekomendasi drama berdasarkan kemiripan dataframe

    Parameter:
    ---
    nama_drama : tipe data string (str)
                Nama Drama (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan drama sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_drama].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_drama agar nama drama yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_drama, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""kita akan menampilkan rekomendasi drama yang mirip dengan kdrama yang berjudul '18 Again'"""

# drop 18 again agar tidak muncul dalam daftar rekomendasi yg diberikan, mau nyari yg mirip sm 18 Again
kdrama_df[kdrama_df.drama_name.eq('18 Again')]

# Mendapatkan rekomendasi drama yang mirip dengan 18 Again
drama_recommendations('18 Again')

"""## Collaborative Filtering

Pada modeling dengan Collaborative filtering kita akan menggunakan pendekatan Neural Collaborative Filtering (NCF). Kita akan menggunakan RecommenderNet untuk mengimplementasikannya
"""

class RecommenderNet(tf_lib.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_drama, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_drama = num_drama
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = tf_lib.keras.regularizers.l2(1e-6) # change keras to tf_lib.keras
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.drama_embedding = layers.Embedding( # layer embeddings drama
        num_drama,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = tf_lib.keras.regularizers.l2(1e-6) # change keras to tf_lib.keras
    )
    self.drama_bias = layers.Embedding(num_drama, 1) # layer embedding drama bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    drama_vector = self.drama_embedding(inputs[:, 1]) # memanggil layer embedding 3
    drama_bias = self.drama_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_drama = tf_lib.tensordot(user_vector, drama_vector, 2) # change tf to tf_lib

    x = dot_user_drama + user_bias + drama_bias

    return tf_lib.nn.sigmoid(x) # activation sigmoid # change tf to tf_lib

"""Inisialisasi model dengan menggunakan Adam optimizer dan RMSE sebagai metrik evaluasi."""

model = RecommenderNet(num_users, num_drama, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf_lib.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf_lib.keras.metrics.RootMeanSquaredError()]
)

"""Lakukan training dengan batch_size bernilai 8 dan 30 epoch"""

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 30, # menggunakan 30
    validation_data = (x_val, y_val)
)

"""# Evaluasi

## Evaluasi CF

Evaluasi Collaborative Filtering (CF) dengan menggunakan Root Mean Squared Error (RMSE)
"""

# Evaluasi pada data validasi
val_loss, val_rmse = model.evaluate(x_val, y_val)
print(f"Validation Loss: {val_loss:.4f}")
print(f"Validation RMSE: {val_rmse:.4f}")

# Evaluasi pada data uji
test_loss, test_rmse = model.evaluate(x_test, y_test)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test RMSE: {test_rmse:.4f}")

"""### Visualisasi Metrik

Buat visualiasi dari hasil evaluasi supaya lebih mudah dibaca
"""

import matplotlib.pyplot as plt

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""### Mendapatkan rekomendasi drama hasil CF

Siapkan data pengguna dan drama yg belum ditonton untuk mendapat rekomendasi dengan CF
"""

drama_df = kdrama_df

user_id = reviews_df['user_id'].sample(1).iloc[0]
drama_watched_by_user = reviews_df[reviews_df['user_id'] == user_id]

drama_not_watched = drama_df[~drama_df['kdrama_id'].isin(drama_watched_by_user['kdrama_encode'].values)]['kdrama_id']
drama_not_watched = list(
    set(drama_not_watched)
    .intersection(set(drama_to_drama_encoded.keys()))
)

drama_not_watched = [[drama_to_drama_encoded.get(x)] for x in drama_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_drama_array = np.hstack(
    ([[user_encoder]] * len(drama_not_watched), drama_not_watched)
)

"""Berikan rekomendasi drama berdasarkan ulasan pengguna, dengan menampilkan drama yang telah ditonton dan rekomendasi drama lainnya yang sesuai dengan preferensi pengguna"""

reviews_model = model.predict(user_drama_array).flatten()

top_reviews_indices = reviews_model.argsort()[-10:][::-1]

recommended_drama_ids = [
    drama_encoded_to_drama.get(drama_not_watched[x][0]) for x in top_reviews_indices
]

top_drama_user = (
    drama_watched_by_user.sort_values(
        by='overall_score',
        ascending=False
    )
    .head(10)['kdrama_encode'].values
)

drama_df_rows = drama_df[drama_df['kdrama_id'].isin(top_drama_user)]

# Displays drama recommendations in DataFrame form
drama_df_rows_data = []
for row in drama_df_rows.itertuples():
    drama_df_rows_data.append([row.drama_name, row.tags])

recommended_drama = drama_df[drama_df['kdrama_id'].isin(recommended_drama_ids)]

recommended_drama_data = []
for row in recommended_drama.itertuples():
    recommended_drama_data.append([row.drama_name, row.tags])

# Create a DataFrame for output
output_columns = ['drama Title', 'drama tags']
df_drama_watched_by_user = pd.DataFrame(drama_df_rows_data, columns=output_columns)
df_recommended_dramas = pd.DataFrame(recommended_drama_data, columns=output_columns)

# Displays recommendation results in DataFrame form
print("Showing recommendation for users: {}".format(user_id))
print("===" * 9)
print("drama with high reviews from user")
print("----" * 8)
print(df_drama_watched_by_user)
print("----" * 8)
print("Top 10 dramas recommendation")
print("----" * 8)
df_recommended_dramas

"""## Evaluasi CBF

Evaluasi CBF menggunakan metriks evaluasi precision, recall, dan F1-score untuk mengukur performa model berdasarkan prediksi yang dihasilkan dari cosine similarity dan ground truth.

Tentukan nilai threshold untuk menghitung matriks ground_truth berdasarkan nilai cosine similarity. Jika ada dua kdrama yang memiliki nilai similarity lebih besar atau sama dengan threshold yang ditentukan, maka keduanya dianggap relevan (diberi label 1 dalam matriks ground_truth).
"""

threshold = 0.6

ground_truth = np.where(cosine_sim >= threshold, 1, 0)

ground_truth_df = pd.DataFrame(ground_truth, index=kdrama_df['drama_name'], columns=kdrama_df['drama_name']).sample(15, axis=1).sample(15, axis=0)

"""ambil subset dari matriks cosine_sim dan ground_truth sebanyak 10.000 data, meratakannya menjadi array satu dimensi, dan kemudian membandingkannya dengan threshold untuk menghasilkan prediksi biner. Prediksi ini kemudian dievaluasi menggunakan metrik precision, recall, dan F1-score untuk mengukur performa model."""

sample_size = 10000
cosine_sim_sample = cosine_sim[:sample_size, :sample_size]
ground_truth_sample = ground_truth[:sample_size, :sample_size]

cosine_sim_flat = cosine_sim_sample.flatten()

ground_truth_flat = ground_truth_sample.flatten()

predictions = (cosine_sim_flat >= threshold).astype(int)
precision, recall, f1, _ = precision_recall_fscore_support(
     ground_truth_flat, predictions, average='binary', zero_division=1
)

print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

"""Berdarkan metriks evaluasi tersebut, model memiliki performa yang sangat baik, dengan precision, recall, dan F1-score semuanya mencapai 1.0, yang menunjukkan bahwa model memberikan rekomendasi dengan sangat baik tanpa kesalahan atau false positive/negative."""